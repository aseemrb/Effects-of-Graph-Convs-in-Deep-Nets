{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vietnamese-cologne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from helpers import *\n",
    "from torch_geometric.datasets import Planetoid\n",
    "torch.set_printoptions(precision=2,sci_mode=False, linewidth=200)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', device)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5482dd5-5833-40b8-a8fd-974a85855c5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learners and Plot Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "supported-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [Planetoid(root='data/Cora/', name='Cora'), Planetoid(root='data/PubMed/', name='PubMed'), Planetoid(root='data/CiteSeer/', name='CiteSeer')]\n",
    "model_types = [\n",
    "    'mlp', # 2 layer MLPs\n",
    "    'gcn2l10', # 2 layer GCN with 1 GC at layer 1\n",
    "    # 'gcn2l01', # 2 layer GCN with 1 GC at layer 2\n",
    "    # 'gcn2l20', # 2 layer GCN with 2 GCs at layer 1\n",
    "    # 'gcn2l02', # 2 layer GCN with 2 GCs at layer 2\n",
    "    # 'gcn2l11', # 2 layer GCN with 1 GC each at layers 1 and 2\n",
    "    # 'gcn3l100', # 3 layer GCN with 1 GC at layer 1\n",
    "    # 'gcn3l010', # 3 layer GCN with 1 GC at layer 2\n",
    "    # 'gcn3l001', # 3 layer GCN with 1 GC at layer 3\n",
    "    # 'gcn3l200', # 3 layer GCN with 2 GCs at layer 1\n",
    "    # 'gcn3l020', # 3 layer GCN with 2 GCs at layer 2\n",
    "    # 'gcn3l002', # 3 layer GCN with 2 GCs at layer 3\n",
    "    # 'gcn3l110', # 3 layer GCN with 1 GC each at layers 1 and 2\n",
    "    # 'gcn3l101', # 3 layer GCN with 1 GC each at layers 1 and 3\n",
    "    # 'gcn3l011', # 3 layer GCN with 1 GC each at layers 2 and 3\n",
    "]\n",
    "\n",
    "# Initialize all learning models.\n",
    "def init_learners(channels_2l, channels_3l):\n",
    "    learners = {}\n",
    "    learners['mlp'] = MLP(n_layers=2, n_features=n_features, channels=channels_2l)\n",
    "    learners['gcn2l10'] = GCN(n_layers=2, n_features=n_features, convolutions=[1, 0], channels=channels_2l)\n",
    "    learners['gcn2l01'] = GCN(n_layers=2, n_features=n_features, convolutions=[0, 1], channels=channels_2l)\n",
    "    learners['gcn2l20'] = GCN(n_layers=2, n_features=n_features, convolutions=[0, 2], channels=channels_2l)\n",
    "    learners['gcn2l02'] = GCN(n_layers=2, n_features=n_features, convolutions=[2, 0], channels=channels_2l)\n",
    "    learners['gcn2l11'] = GCN(n_layers=2, n_features=n_features, convolutions=[1, 1], channels=channels_2l)\n",
    "    learners['gcn3l100'] = GCN(n_layers=3, n_features=n_features, convolutions=[1, 0, 0], channels=channels_3l)\n",
    "    learners['gcn3l010'] = GCN(n_layers=3, n_features=n_features, convolutions=[0, 1, 0], channels=channels_3l)\n",
    "    learners['gcn3l001'] = GCN(n_layers=3, n_features=n_features, convolutions=[0, 0, 1], channels=channels_3l)\n",
    "    learners['gcn3l200'] = GCN(n_layers=3, n_features=n_features, convolutions=[2, 0, 0], channels=channels_3l)\n",
    "    learners['gcn3l020'] = GCN(n_layers=3, n_features=n_features, convolutions=[0, 2, 0], channels=channels_3l)\n",
    "    learners['gcn3l002'] = GCN(n_layers=3, n_features=n_features, convolutions=[0, 0, 2], channels=channels_3l)\n",
    "    learners['gcn3l110'] = GCN(n_layers=3, n_features=n_features, convolutions=[1, 1, 0], channels=channels_3l)\n",
    "    learners['gcn3l101'] = GCN(n_layers=3, n_features=n_features, convolutions=[1, 0, 1], channels=channels_3l)\n",
    "    learners['gcn3l011'] = GCN(n_layers=3, n_features=n_features, convolutions=[0, 1, 1], channels=channels_3l)\n",
    "    return learners\n",
    "\n",
    "line_wd = 2 # line width for plots.\n",
    "marker_sz = 4 # marker size for plots.\n",
    "labels = {\n",
    "    'mlp': 'No Graph',\n",
    "    'gcn2l10': '2 layers 1 GC at layer 1',\n",
    "    'gcn2l01': '2 layers 1 GC at layer 2',\n",
    "    'gcn2l20': '2 layers 2 GCs at layer 1',\n",
    "    'gcn2l02': '2 layers 2 GCs at layer 2',\n",
    "    'gcn2l11': '2 layers 1 GC each at layers 1 and 2',\n",
    "    'gcn3l100': '3 layers 1 GC at layer 1',\n",
    "    'gcn3l010': '3 layers 1 GC at layer 2',\n",
    "    'gcn3l001': '3 layers 1 GC at layer 3',\n",
    "    'gcn3l200': '3 layers 2 GCs at layer 1',\n",
    "    'gcn3l020': '3 layers 2 GCs at layer 2',\n",
    "    'gcn3l002': '3 layers 2 GCs at layer 3',\n",
    "    'gcn3l110': '3 layers 1 GC each at layers 1 and 2',\n",
    "    'gcn3l101': '3 layers 1 GC each at layers 1 and 3',\n",
    "    'gcn3l011': '3 layers 1 GC each at layers 2 and 3',\n",
    "}\n",
    "\n",
    "def plot_for_models(x, ys, yerrs, x_label, y_label, labels, filename=None):\n",
    "    fig = plt.figure(figsize=(20,5), facecolor=[1,1,1])\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    plt.xlabel(x_label, fontsize=18)\n",
    "    plt.ylabel(y_label, fontsize=18)\n",
    "    \n",
    "    for model_type in model_types:\n",
    "        y = np.asarray(ys[model_type])\n",
    "        yerr = np.asarray(yerrs[model_type])\n",
    "        plt.plot(x, y, linewidth=line_wd, linestyle= '-', marker='.', markersize=marker_sz, label=labels[model_type])\n",
    "        plt.fill_between(x, y - yerr, y + yerr, alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    if filename is not None:\n",
    "        fig.savefig(\"figures/\" + filename, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c83d3-db7a-4870-a111-440c21d52338",
   "metadata": {},
   "source": [
    "## Train and test all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6450439a-ac8d-464b-bd02-603c3bbcdd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cora: Classes = 7 | Points = 2708 | Features = 1433\n",
      "\n",
      "Working for Cora class 0\n",
      "Progress (class 0, gcn2l10): 20.0%. Loss: 0.002\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "# Fix max number of epochs, and number of trials.\n",
    "epochs = 1000\n",
    "n_trials = 10\n",
    "\n",
    "# Metrics to plot.\n",
    "train_acc = {}\n",
    "train_acc_std = {}\n",
    "train_loss = {}\n",
    "train_loss_std = {}\n",
    "test_acc = {}\n",
    "test_acc_std = {}\n",
    "test_loss = {}\n",
    "test_loss_std = {}\n",
    "Ks = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    data = dataset[0].to(device)\n",
    "    data.x_orig = copy.deepcopy(data.x)\n",
    "    n_points, n_features = data.x.shape\n",
    "    n_classes = data.y.max() + 1\n",
    "    print('\\n' + dataset.name + ': Classes =', n_classes.item(), '| Points =', n_points, '| Features =', n_features)\n",
    "    train_acc[dataset.name] = {}\n",
    "    train_acc_std[dataset.name] = {}\n",
    "    train_loss[dataset.name] = {}\n",
    "    train_loss_std[dataset.name] = {}\n",
    "    test_acc[dataset.name] = {}\n",
    "    test_acc_std[dataset.name] = {}\n",
    "    test_loss[dataset.name] = {}\n",
    "    test_loss_std[dataset.name] = {}\n",
    "    Ks[dataset.name] = {}\n",
    "\n",
    "    for class_label in range(n_classes):\n",
    "        print(\"\\nWorking for\", dataset.name, 'class', class_label)\n",
    "        train_acc[dataset.name][class_label] = {}\n",
    "        train_acc_std[dataset.name][class_label] = {}\n",
    "        train_loss[dataset.name][class_label] = {}\n",
    "        train_loss_std[dataset.name][class_label] = {}\n",
    "        test_acc[dataset.name][class_label] = {}\n",
    "        test_acc_std[dataset.name][class_label] = {}\n",
    "        test_loss[dataset.name][class_label] = {}\n",
    "        test_loss_std[dataset.name][class_label] = {}\n",
    "        y = torch.zeros(n_points).to(device)\n",
    "        idx_mask = data.y == class_label\n",
    "        y[idx_mask] = 1\n",
    "        data.y_ = y\n",
    "        u = data.x_orig[idx_mask].mean(dim=0)\n",
    "        v = data.x_orig[~idx_mask].mean(dim=0)\n",
    "        \n",
    "        # Fix network architectures for the networks.\n",
    "        channels_2l = [[n_features, 16], [16, 1]]\n",
    "        channels_3l = [[n_features, 16, 16], [16, 16, 1]]\n",
    "        \n",
    "        train_acc_list = {}\n",
    "        train_loss_list = {}\n",
    "        test_acc_list = {}\n",
    "        test_loss_list = {}\n",
    "        for model_type in model_types:\n",
    "            train_acc[dataset.name][class_label][model_type] = []\n",
    "            train_acc_std[dataset.name][class_label][model_type] = []\n",
    "            train_loss[dataset.name][class_label][model_type] = []\n",
    "            train_loss_std[dataset.name][class_label][model_type] = []\n",
    "            test_acc[dataset.name][class_label][model_type] = []\n",
    "            test_acc_std[dataset.name][class_label][model_type] = []\n",
    "            test_loss[dataset.name][class_label][model_type] = []\n",
    "            test_loss_std[dataset.name][class_label][model_type] = []\n",
    "        \n",
    "        dist = torch.norm(u-v)\n",
    "        K = dist/(2*np.sqrt(n_features))\n",
    "        K_ub = 10*K\n",
    "        K_lb = 0.01*K\n",
    "        Ks[dataset.name][class_label] = np.geomspace(K_lb, K_ub, 5)\n",
    "        for (i, K) in enumerate(Ks[dataset.name][class_label]):\n",
    "            u_ = K*torch.ones(n_features).to(device)\n",
    "            v_ = -K*torch.ones(n_features).to(device)\n",
    "            data.x[idx_mask] = data.x_orig[idx_mask] - u + u_\n",
    "            data.x[~idx_mask] = data.x_orig[~idx_mask] - v + v_\n",
    "            \n",
    "            for model_type in model_types:\n",
    "                train_acc_list[model_type] = torch.zeros(n_trials)\n",
    "                train_loss_list[model_type] = torch.zeros(n_trials)\n",
    "                test_acc_list[model_type] = torch.zeros(n_trials)\n",
    "                test_loss_list[model_type] = torch.zeros(n_trials)\n",
    "            \n",
    "            for t in range(n_trials):\n",
    "                logs = 'Progress (class ' + str(class_label) + ', ' + model_type + '): ' + str(round(100*(t)*(i+1)/(len(Ks)*n_trials), 2)) + '%.'\n",
    "                learners = init_learners(channels_2l, channels_3l)\n",
    "                for model_type in model_types:\n",
    "                    learner = learners[model_type].to(device)\n",
    "                    train_model(learner, data, loss_fn, lr=0.01, epochs=epochs, logs=logs)\n",
    "                    learner.eval()\n",
    "                    pred = learner(data)\n",
    "                    train_acc_list[model_type][t] = accuracy(pred[data.train_mask], data.y_[data.train_mask]).item()\n",
    "                    train_loss_list[model_type][t] = loss_fn(pred[data.train_mask], data.y_[data.train_mask].float()).item()\n",
    "                    test_acc_list[model_type][t] = accuracy(pred[data.test_mask], data.y_[data.test_mask]).item()\n",
    "                    test_loss_list[model_type][t] = loss_fn(pred[data.test_mask], data.y_[data.test_mask].float()).item()\n",
    "            \n",
    "            for model_type in model_types:\n",
    "                train_acc[dataset.name][class_label][model_type].append(train_acc_list[model_type].mean().item())\n",
    "                train_acc_std[dataset.name][class_label][model_type].append(train_acc_list[model_type].std(unbiased=False).item())\n",
    "                train_loss[dataset.name][class_label][model_type].append(train_loss_list[model_type].mean().item())\n",
    "                train_loss_std[dataset.name][class_label][model_type].append(train_loss_list[model_type].std(unbiased=False).item())\n",
    "                test_acc[dataset.name][class_label][model_type].append(test_acc_list[model_type].mean().item())\n",
    "                test_acc_std[dataset.name][class_label][model_type].append(test_acc_list[model_type].std(unbiased=False).item())\n",
    "                test_loss[dataset.name][class_label][model_type].append(test_loss_list[model_type].mean().item())\n",
    "                test_loss_std[dataset.name][class_label][model_type].append(test_loss_list[model_type].std(unbiased=False).item())\n",
    "        \n",
    "        # Plot the metrics for this dataset and class label.\n",
    "        filename = dataset.name + '_cls' + str(class_label) + '_train_acc.pdf' # Can be replaced with filename (with extension, e.g. 'fig.pdf') to save the next plot.\n",
    "        plot_for_models(\n",
    "            Ks[dataset.name][class_label],\n",
    "            train_acc[dataset.name][class_label],\n",
    "            train_acc_std[dataset.name][class_label],\n",
    "            'Dist b/w means', 'Training Accuracy',\n",
    "            labels, filename)\n",
    "        filename = dataset.name + '_cls' + str(class_label) + '_test_acc.pdf' # Can be replaced with filename (with extension, e.g. 'fig.pdf') to save the next plot.\n",
    "        plot_for_models(\n",
    "            Ks[dataset.name][class_label],\n",
    "            test_acc[dataset.name][class_label],\n",
    "            test_acc_std[dataset.name][class_label],\n",
    "            'Dist b/w means', 'Test Accuracy',\n",
    "            labels, filename)\n",
    "        filename = dataset.name + '_cls' + str(class_label) + '_train_loss.pdf' # Can be replaced with filename (with extension, e.g. 'fig.pdf') to save the next plot.\n",
    "        plot_for_models(\n",
    "            Ks[dataset.name][class_label],\n",
    "            train_loss[dataset.name][class_label],\n",
    "            train_loss_std[dataset.name][class_label],\n",
    "            'Dist b/w means', 'Training Loss',\n",
    "            labels, filename)\n",
    "        filename = dataset.name + '_cls' + str(class_label) + '_test_loss.pdf' # Can be replaced with filename (with extension, e.g. 'fig.pdf') to save the next plot.\n",
    "        plot_for_models(\n",
    "            Ks[dataset.name][class_label],\n",
    "            test_acc[dataset.name][class_label],\n",
    "            test_acc_std[dataset.name][class_label],\n",
    "            'Dist b/w means', 'Test Loss',\n",
    "            labels, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64cccfe-27c0-4235-aaff-4b352e765cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
