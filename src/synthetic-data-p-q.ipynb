{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vietnamese-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "torch.set_printoptions(precision=2,sci_mode=False, linewidth=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5482dd5-5833-40b8-a8fd-974a85855c5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "supported-machinery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_points: 400\n",
      "n_features: 12\n"
     ]
    }
   ],
   "source": [
    "n_points = 400\n",
    "n_features = 12\n",
    "n_train_sets = 5\n",
    "n_test_trials = 20\n",
    "print(\"n_points:\", n_points)\n",
    "print(\"n_features:\", n_features)\n",
    "\n",
    "# Fix the variance to 1/n_features.\n",
    "sig_sq = 1.0/n_features\n",
    "\n",
    "# dist_sd_ratio = K, where norm(u-v) = K*sigma.\n",
    "K = np.log(n_points)\n",
    "ps = np.linspace(5, 100, num=20, dtype=int)\n",
    "qs = np.linspace(0, 100, num=21, dtype=int)\n",
    "data_model = {}\n",
    "for (p, q) in itertools.product(ps, qs):\n",
    "    p_ = p/100.\n",
    "    q_ = q/100.\n",
    "    data_model[(p,q)] = XCSBM(n_points, n_features, K, sig_sq, p_, q_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f215eff-a6b8-4380-84e0-8964ed493aab",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe597209-3dc4-4821-8b27-705ce5203bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training 420 MLP and GCN models...\n",
      "Idx: 100,100 , Loss: 0.6931471824645996265.025744523853063583"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', device)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Models.\n",
    "gcns_2l_1c = {} # 2 layer GCN with 1 GC at layer 2\n",
    "gcns_2l_2c = {} # 2 layer GCN with 2 GCs at layer 2\n",
    "gcns_3l_1c = [{}, {}] # 3 layer GCN with 1, 1 GC at layer 2 or 3\n",
    "gcns_3l_2c = [{}, {}, {}] # 3 layer GCN with 2 GCs at layer 2, 3 or 1 GC at each layer\n",
    "train_loss_gcn_2l = [{}, {}]\n",
    "train_loss_gcn_3l_1c = [{}, {}]\n",
    "train_loss_gcn_3l_2c = [{}, {}, {}]\n",
    "\n",
    "# Fix network architectures for the networks.\n",
    "channels_2l = [[n_features, 4], [4, 1]]\n",
    "channels_3l = [[n_features, 4, 2], [4, 2, 1]]\n",
    "\n",
    "print('Training', len(data_model), 'MLP and GCN models...')\n",
    "for (p, q) in itertools.product(ps, qs):\n",
    "    if p < q:\n",
    "        continue\n",
    "    # 2-layer GCN with 1 GC\n",
    "    # Initialize with ansatz based on u, v.\n",
    "    model = GCN(n_layers=2, n_features=n_features, convolutions=[0, 1], channels=channels_2l)\n",
    "    set_params(model, data_model[(p,q)], n_layers=2)\n",
    "    for t in range(n_train_sets):\n",
    "        data = data_model[(p,q)].generate_data()\n",
    "        train_model(model, data, loss_fn, idx=str(p)+','+str(q))\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out, data.y.float())\n",
    "    train_loss_gcn_2l[0][(p,q)] = loss.item()\n",
    "    gcns_2l_1c[(p,q)] = model\n",
    "    \n",
    "    # 2-layer GCN with 2 GCs\n",
    "    # Initialize with ansatz based on u, v.\n",
    "    model = GCN(n_layers=2, n_features=n_features, convolutions=[0, 2], channels=channels_2l)\n",
    "    set_params(model, data_model[(p,q)], n_layers=2)\n",
    "    for t in range(n_train_sets):\n",
    "        data = data_model[(p,q)].generate_data()\n",
    "        train_model(model, data, loss_fn, idx=str(p)+','+str(q))\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out, data.y.float())\n",
    "    train_loss_gcn_2l[1][(p,q)] = loss.item()\n",
    "    gcns_2l_2c[(p,q)] = model\n",
    "    \n",
    "    # 3-layer GCN with 1 GC at layer 2\n",
    "    model = GCN(n_layers=3, n_features=n_features, convolutions=[0, 1, 0], channels=channels_3l)\n",
    "    set_params(model, data_model[(p,q)], n_layers=3)\n",
    "    for t in range(n_train_sets):\n",
    "        data = data_model[(p,q)].generate_data()\n",
    "        train_model(model, data, loss_fn, idx=str(p)+','+str(q))\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out, data.y.float())\n",
    "    train_loss_gcn_3l_1c[0][(p,q)] = loss.item()\n",
    "    gcns_3l_1c[0][(p,q)] = model\n",
    "    \n",
    "    # 3-layer GCN with 1 GC at layer 3\n",
    "    model = GCN(n_layers=3, n_features=n_features, convolutions=[0, 0, 1], channels=channels_3l)\n",
    "    set_params(model, data_model[(p,q)], n_layers=3)\n",
    "    for t in range(n_train_sets):\n",
    "        data = data_model[(p,q)].generate_data()\n",
    "        train_model(model, data, loss_fn, idx=str(p)+','+str(q))\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out, data.y.float())\n",
    "    train_loss_gcn_3l_1c[1][(p,q)] = loss.item()\n",
    "    gcns_3l_1c[1][(p,q)] = model\n",
    "    \n",
    "    # 3-layer GCN with 2 GC at layer 2\n",
    "    model = GCN(n_layers=3, n_features=n_features, convolutions=[0, 2, 0], channels=channels_3l)\n",
    "    set_params(model, data_model[(p,q)], n_layers=3)\n",
    "    for t in range(n_train_sets):\n",
    "        data = data_model[(p,q)].generate_data()\n",
    "        train_model(model, data, loss_fn, idx=str(p)+','+str(q))\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out, data.y.float())\n",
    "    train_loss_gcn_3l_2c[0][(p,q)] = loss.item()\n",
    "    gcns_3l_2c[0][(p,q)] = model\n",
    "    \n",
    "    # 3-layer GCN with 2 GC at layer 3\n",
    "    model = GCN(n_layers=3, n_features=n_features, convolutions=[0, 0, 2], channels=channels_3l)\n",
    "    set_params(model, data_model[(p,q)], n_layers=3)\n",
    "    for t in range(n_train_sets):\n",
    "        data = data_model[(p,q)].generate_data()\n",
    "        train_model(model, data, loss_fn, idx=str(p)+','+str(q))\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out, data.y.float())\n",
    "    train_loss_gcn_3l_2c[1][(p,q)] = loss.item()\n",
    "    gcns_3l_2c[1][(p,q)] = model\n",
    "    \n",
    "    # 3-layer GCN with 1 + 1 GC at layers 1 and 3\n",
    "    model = GCN(n_layers=3, n_features=n_features, convolutions=[0, 1, 1], channels=channels_3l)\n",
    "    set_params(model, data_model[(p,q)], n_layers=3)\n",
    "    for t in range(n_train_sets):\n",
    "        data = data_model[(p,q)].generate_data()\n",
    "        train_model(model, data, loss_fn, idx=str(p)+','+str(q))\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out, data.y.float())\n",
    "    train_loss_gcn_3l_2c[2][(p,q)] = loss.item()\n",
    "    gcns_3l_2c[2][(p,q)] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe517391-ebc7-4183-8885-bfa7b8d57280",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "descending-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_gcn_2l = [{}, {}]\n",
    "test_loss_gcn_3l_1c = [{}, {}]\n",
    "test_loss_gcn_3l_2c = [{}, {}, {}]\n",
    "for (p,q) in itertools.product(ps, qs):\n",
    "    if p < q:\n",
    "        continue\n",
    "    loss_mlp = 0\n",
    "    loss_gcn_2l = [0, 0]\n",
    "    loss_gcn_3l_1c = [0, 0]\n",
    "    loss_gcn_3l_2c = [0, 0, 0]\n",
    "    for t in range(n_test_trials):\n",
    "        data = data_model[(p,q)].generate_data()\n",
    "        \n",
    "        # Loss of GCNs on the test dataset.\n",
    "        pred = gcns_2l_1c[(p,q)](data)\n",
    "        loss_gcn_2l[0] += loss_fn(pred, data.y.float()).item()\n",
    "        pred = gcns_2l_2c[(p,q)](data)\n",
    "        loss_gcn_2l[1] += loss_fn(pred, data.y.float()).item()\n",
    "        pred = gcns_3l_1c[0][(p,q)](data)\n",
    "        loss_gcn_3l_1c[0] += loss_fn(pred, data.y.float()).item()\n",
    "        pred = gcns_3l_1c[1][(p,q)](data)\n",
    "        loss_gcn_3l_1c[1] += loss_fn(pred, data.y.float()).item()\n",
    "        pred = gcns_3l_2c[0][(p,q)](data)\n",
    "        loss_gcn_3l_2c[0] += loss_fn(pred, data.y.float()).item()\n",
    "        pred = gcns_3l_2c[1][(p,q)](data)\n",
    "        loss_gcn_3l_2c[1] += loss_fn(pred, data.y.float()).item()\n",
    "        pred = gcns_3l_2c[2][(p,q)](data)\n",
    "        loss_gcn_3l_2c[2] += loss_fn(pred, data.y.float()).item()\n",
    "    \n",
    "    test_loss_gcn_2l[0][(p,q)] = loss_gcn_2l[0]/n_test_trials\n",
    "    test_loss_gcn_2l[1][(p,q)] = loss_gcn_2l[1]/n_test_trials\n",
    "    test_loss_gcn_3l_1c[0][(p,q)] = loss_gcn_3l_1c[0]/n_test_trials\n",
    "    test_loss_gcn_3l_1c[1][(p,q)] = loss_gcn_3l_1c[1]/n_test_trials\n",
    "    test_loss_gcn_3l_2c[0][(p,q)] = loss_gcn_3l_2c[0]/n_test_trials\n",
    "    test_loss_gcn_3l_2c[1][(p,q)] = loss_gcn_3l_2c[1]/n_test_trials\n",
    "    test_loss_gcn_3l_2c[2][(p,q)] = loss_gcn_3l_2c[2]/n_test_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c61bf-a884-440b-87a1-00aa0bf12dac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparison of the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38d69bea-4308-4f8a-8ca0-5c8b3e4f82ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0.05, 0.1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w3/c7ng27q12xzdp16_sx_wdvt00000gn/T/ipykernel_2090/4005209399.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Fixed q and changing p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0myaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_loss_gcn_2l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mxaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w3/c7ng27q12xzdp16_sx_wdvt00000gn/T/ipykernel_2090/4005209399.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Fixed q and changing p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0myaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_loss_gcn_2l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mxaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.05, 0.1)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lw = 1 # line width for plots.\n",
    "ms = 2 # marker size for plots.\n",
    "\n",
    "fig = plt.figure(figsize=(20,5), facecolor=[1,1,1])\n",
    "gs = fig.add_gridspec(1, 2, hspace=0)\n",
    "axs = gs.subplots(sharex=True)\n",
    "for i in range(2):\n",
    "    axs[i].set_xscale('log')\n",
    "    axs[i].set_yscale('log')\n",
    "\n",
    "# Fixed q and changing p\n",
    "q=qs[2]\n",
    "yaxis = [train_loss_gcn_2l[0][(p,q)] for p in ps]\n",
    "xaxis = [p/100. for p in ps if p >= q]\n",
    "\n",
    "train_loss_gcn_2l[0]\n",
    "axs[0].plot(xaxis, yaxis, linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 2 layers 1 conv at layer 2')\n",
    "# axs[0].plot(dist_sd_ratios, train_loss_gcn_2l[1], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 2 layers 2 convs at layer 2')\n",
    "# axs[0].plot(dist_sd_ratios, train_loss_gcn_3l_1c[0], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 3 layers 1 conv at layer 2')\n",
    "# axs[0].plot(dist_sd_ratios, train_loss_gcn_3l_1c[1], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 3 layers 1 conv at layer 3')\n",
    "# axs[0].plot(dist_sd_ratios, train_loss_gcn_3l_2c[0], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 3 layers 2 convs at layer 2')\n",
    "# axs[0].plot(dist_sd_ratios, train_loss_gcn_3l_2c[1], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 3 layers 2 convs at layer 3')\n",
    "# axs[0].plot(dist_sd_ratios, train_loss_gcn_3l_2c[2], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 3 layers 1 conv each at layer 2 and 3')\n",
    "axs[0].set_ylabel(r'Train Loss', fontsize=18)\n",
    "\n",
    "yaxis = [test_loss_gcn_2l[0][(p,q)] for p in ps]\n",
    "axs[1].plot(xaxis, yaxis, linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 2 layers 1 conv at layer 2')\n",
    "# axs[1].plot(dist_sd_ratios, test_loss_gcn_2l[1], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 2 layers 2 convs at layer 2')\n",
    "# axs[1].plot(dist_sd_ratios, test_loss_gcn_3l_1c[0], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 3 layers 1 conv at layer 2')\n",
    "# axs[1].plot(dist_sd_ratios, test_loss_gcn_3l_1c[1], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 3 layers 1 conv at layer 3')\n",
    "# axs[1].plot(dist_sd_ratios, test_loss_gcn_3l_2c[0], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 3 layers 2 convs at layer 2')\n",
    "# axs[1].plot(dist_sd_ratios, test_loss_gcn_3l_2c[1], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 3 layers 2 convs at layer 3')\n",
    "# axs[1].plot(dist_sd_ratios, test_loss_gcn_3l_2c[2], linewidth=lw, linestyle= '-', marker='.', markersize=ms, label='GCN 3 layers 1 conv each at layer 2 and 3')\n",
    "axs[1].set_ylabel(r'Test Loss', fontsize=18)\n",
    "for i in range(2):\n",
    "    # axs[i].axvline(x=np.log(n_points), color='red', linewidth=4, linestyle='-.', alpha=0.5, label=r'$\\log(n)$')\n",
    "    axs[i].axvline(x=np.sqrt(np.log(n_points)), color='red', linewidth=4, linestyle='-.', alpha=.8, label=r'$\\sqrt{\\log(n)}$')\n",
    "    axs[i].axvline(\n",
    "        x=np.sqrt(np.log(n_points)/np.sqrt(.5*n_points*(p+q))),\n",
    "        color='purple', linewidth=4, linestyle='-.', alpha=.8,\n",
    "        label=r'$\\sqrt{\\log(n)}/\\sqrt[4]{0.5n(p+q)}$')\n",
    "    # axs[i].axvline(\n",
    "    #     x=np.sqrt(np.log(n_points)/np.sqrt(n_points)),\n",
    "    #     color='violet', linewidth=4, linestyle='-.', alpha=1,\n",
    "    #     label=r'$\\sqrt{\\log(n)}/\\sqrt[4]{n}$')\n",
    "    axs[i].set_xlabel(r'$K = \\frac{\\Vert u-v \\Vert_2}{\\sigma}$', fontsize=18)\n",
    "    axs[i].legend()\n",
    "fig.savefig(\"../figures/synthetic_data_mlp_vs_gcn.pdf\", dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90c462-e361-4eb3-8d24-561d472e5689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
