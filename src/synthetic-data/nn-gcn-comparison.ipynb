{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vietnamese-cologne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "import pickle\n",
    "torch.set_printoptions(precision=2,sci_mode=False, linewidth=200)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', device)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5482dd5-5833-40b8-a8fd-974a85855c5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Model and Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "supported-machinery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_points: 200\n",
      "n_features: 4\n"
     ]
    }
   ],
   "source": [
    "n_points = 800\n",
    "n_features = 12\n",
    "n_train_sets = 10\n",
    "n_test_trials = 10\n",
    "print(\"n_points:\", n_points)\n",
    "print(\"n_features:\", n_features)\n",
    "\n",
    "# Fix the variance to 1/n_features.\n",
    "sig_sq = 1.0/n_features\n",
    "\n",
    "# dist_sd_ratio = K, where norm(u-v) = K*sigma.\n",
    "dist_sd_ratios = np.logspace(-1, .05 + .5*np.log(np.log(n_points)), num=30)\n",
    "# dist_sd_ratios = np.linspace(1./10., 1.2*np.log(n_points), num=100)\n",
    "data_model = {}\n",
    "p = .5\n",
    "q = .1\n",
    "for K in dist_sd_ratios:\n",
    "    data_model[K] = XCSBM(n_points, n_features, K, sig_sq, p, q)\n",
    "\n",
    "# Learning models.\n",
    "learners = {\n",
    "    'mlp': {}, # 2 layer MLPs\n",
    "    'gcn2l01': {}, # 2 layer GCN with 1 GC at layer 2\n",
    "    'gcn2l02': {}, # 2 layer GCN with 2 GCs at layer 2\n",
    "    'gcn3l010': {}, # 3 layer GCN with 1 GC at layer 2\n",
    "    'gcn3l001': {}, # 3 layer GCN with 1 GC at layer 3\n",
    "    'gcn3l020': {}, # 3 layer GCN with 2 GCs at layer 2\n",
    "    'gcn3l002': {}, # 3 layer GCN with 2 GCs at layer 3\n",
    "    'gcn3l011': {} # 3 layer GCN with 1 GC each at layers 2 and 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f215eff-a6b8-4380-84e0-8964ed493aab",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c5c030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 5 MLP and GCN models...\n",
      "Training 5.5/5.5 gcn3l011 models...\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "train_acc = {}\n",
    "train_acc_std = {}\n",
    "train_loss = {}\n",
    "train_loss_std = {}\n",
    "\n",
    "# Fix network architectures for the networks.\n",
    "channels_2l = [[n_features, 4], [4, 1]]\n",
    "channels_3l = [[n_features, 4, 2], [4, 2, 1]]\n",
    "\n",
    "for model_type in learners:\n",
    "    train_acc[model_type] = []\n",
    "    train_acc_std[model_type] = []\n",
    "    train_loss[model_type] = []\n",
    "    train_loss_std[model_type] = []\n",
    "    for K in dist_sd_ratios:\n",
    "        learners[model_type][K] = []\n",
    "\n",
    "for K in dist_sd_ratios:\n",
    "    for i in range(n_train_sets):\n",
    "        learners['mlp'][K].append(MLP(n_layers=2, n_features=n_features, channels=channels_2l))\n",
    "        learners['gcn2l01'][K].append(GCN(n_layers=2, n_features=n_features, convolutions=[0, 1], channels=channels_2l))\n",
    "        learners['gcn2l02'][K].append(GCN(n_layers=2, n_features=n_features, convolutions=[0, 2], channels=channels_2l))\n",
    "        learners['gcn3l010'][K].append(GCN(n_layers=3, n_features=n_features, convolutions=[0, 1, 0], channels=channels_3l))\n",
    "        learners['gcn3l001'][K].append(GCN(n_layers=3, n_features=n_features, convolutions=[0, 0, 1], channels=channels_3l))\n",
    "        learners['gcn3l020'][K].append(GCN(n_layers=3, n_features=n_features, convolutions=[0, 2, 0], channels=channels_3l))\n",
    "        learners['gcn3l002'][K].append(GCN(n_layers=3, n_features=n_features, convolutions=[0, 0, 2], channels=channels_3l))\n",
    "        learners['gcn3l011'][K].append(GCN(n_layers=3, n_features=n_features, convolutions=[0, 1, 1], channels=channels_3l))\n",
    "\n",
    "print('Training', len(dist_sd_ratios), 'MLP and GCN models...')\n",
    "\n",
    "for (j, K) in enumerate(dist_sd_ratios):\n",
    "    for model_type in learners:\n",
    "        acc_list = torch.zeros(n_train_sets)\n",
    "        loss_list = torch.zeros(n_train_sets)\n",
    "        data = data_model[K].generate_data().to(device)\n",
    "        for t in range(n_train_sets):\n",
    "            print('\\rTraining ' + str(j+1) + '.' + str(t+1) +  '/' + str(len(dist_sd_ratios)) + '.' + str(n_train_sets), model_type, 'models...', end='\\r')\n",
    "            learner = learners[model_type][K][t].to(device)\n",
    "            # set_params(learner, data_model[K], n_layers=learner.n_layers, device=device)\n",
    "            train_model(learner, data, loss_fn, lr=0.01, epochs=epochs)\n",
    "            learner.eval()\n",
    "            pred = learner(data)\n",
    "            acc_list[t] = accuracy(pred, data.y).item()\n",
    "            loss_list[t] = loss_fn(pred, data.y.float()).item()\n",
    "        \n",
    "        train_acc[model_type].append(acc_list.mean().item())\n",
    "        train_acc_std[model_type].append(acc_list.std(unbiased=False).item())\n",
    "        train_loss[model_type].append(loss_list.mean().item())\n",
    "        train_loss_std[model_type].append(loss_list.std(unbiased=False).item())\n",
    "\n",
    "print('\\nTraining complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1589c-e18b-495b-9056-f3f33d37bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data-models and learners to disk to avoid retraining.\n",
    "# path_learners = 'learners/'\n",
    "# path_datagens = 'datagen/'\n",
    "# for (j, K) in enumerate(dist_sd_ratios):\n",
    "#     u = data_model[K].normed_uv[0].cpu().numpy().tolist()\n",
    "#     v = data_model[K].normed_uv[1].cpu().numpy().tolist()\n",
    "#     pickle.dump(u, open(path_datagens + 'u' + str(j) + '.data', \"wb\"))\n",
    "#     pickle.dump(v, open(path_datagens + 'v' + str(j) + '.data', \"wb\"))\n",
    "#     for model_type in learners:\n",
    "#         for t in n_train_sets:\n",
    "#             print('\\rSaving model', model_type + '_' + str(j) + '_' + str(t), end='')\n",
    "#             torch.save(learners[model_type][K], path_learners + model_type + '_' + str(j) + '_' + str(t))\n",
    "# print('\\nSaving complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7217827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data-models and learners from disk if saved.\n",
    "# path_learners = 'learners/'\n",
    "# path_datagens = 'datagen/'\n",
    "# for (j, K) in enumerate(dist_sd_ratios):\n",
    "#     u = torch.tensor(pickle.load(open(path_datagens + 'u' + str(j) + '.data', \"rb\")))\n",
    "#     v = torch.tensor(pickle.load(open(path_datagens + 'v' + str(j) + '.data', \"rb\")))\n",
    "#     data_model[K].normed_uv = torch.stack((u, v))\n",
    "#     for model_type in learners:\n",
    "#         learners[model_type][K] = [0]*n_train_sets\n",
    "#         for t in n_train_sets:\n",
    "#             learner = torch.load(path_learners + model_type + '_' + str(j))\n",
    "#             learner.eval()\n",
    "#             learners[model_type][K][t] = learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe517391-ebc7-4183-8885-bfa7b8d57280",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40deba59-07e3-46bd-b734-141e19532e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = {}\n",
    "test_acc_std = {}\n",
    "test_loss = {}\n",
    "test_loss_std = {}\n",
    "    \n",
    "for model_type in learners:\n",
    "    test_acc[model_type] = []\n",
    "    test_acc_std[model_type] = []\n",
    "    test_loss[model_type] = []\n",
    "    test_loss_std[model_type] = []\n",
    "    for (j, K) in enumerate(dist_sd_ratios):\n",
    "        print('\\rEvaluating', j+1, '/', len(dist_sd_ratios), model_type, 'models...', end='')\n",
    "        avg_acc_list = torch.zeros(n_test_trials)\n",
    "        avg_loss_list = torch.zeros(n_test_trials)\n",
    "        for tt in range(n_test_trials):\n",
    "            data = data_model[K].generate_data().to(device)\n",
    "            acc_list = torch.zeros(n_train_sets)\n",
    "            loss_list = torch.zeros(n_train_sets)\n",
    "            for ts in range(n_train_sets):\n",
    "                learner = learners[model_type][K][ts].to(device)\n",
    "                pred = learner(data)\n",
    "                acc_list[ts] = accuracy(pred, data.y).item()\n",
    "                loss_list[ts] = loss_fn(pred, data.y.float()).item()\n",
    "            \n",
    "            avg_acc_list[tt] = acc_list.mean().item()\n",
    "            avg_loss_list[tt] = loss_list.mean().item()\n",
    "\n",
    "        test_acc[model_type].append(avg_acc_list.mean().item())\n",
    "        test_acc_std[model_type].append(avg_acc_list.std(unbiased=False).item())\n",
    "        test_loss[model_type].append(avg_loss_list.mean().item())\n",
    "        test_loss_std[model_type].append(avg_loss_list.std(unbiased=False).item())\n",
    "\n",
    "print('\\nEvaluation complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a09c3f-d119-4020-ac1a-3c76d751ef3f",
   "metadata": {},
   "source": [
    "## Plotting helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38d69bea-4308-4f8a-8ca0-5c8b3e4f82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_wd = 2 # line width for plots.\n",
    "marker_sz = 4 # marker size for plots.\n",
    "labels = {\n",
    "    'mlp': 'MLP',\n",
    "    'gcn2l01': 'GCN 2 layers 1 conv at layer 2',\n",
    "#     'gcn2l02': 'GCN 2 layers 2 convs at layer 2',\n",
    "    'gcn3l010': 'GCN 3 layers 1 conv at layer 2',\n",
    "    'gcn3l001': 'GCN 3 layers 1 conv at layer 3',\n",
    "#     'gcn3l020': 'GCN 3 layers 2 convs at layer 2',\n",
    "#     'gcn3l002': 'GCN 3 layers 2 convs at layer 3',\n",
    "#     'gcn3l011': 'GCN 3 layers 1 conv each at layer 2 and 3'\n",
    "}\n",
    "\n",
    "def plot_with_std(ax, x, y, yerr, label):\n",
    "    y = np.asarray(y)\n",
    "    yerr = np.asarray(yerr)\n",
    "    ax.plot(x, y, linewidth=line_wd, linestyle= '-', marker='.', markersize=marker_sz, label=label)\n",
    "    ax.fill_between(x, y - yerr, y + yerr, alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c61bf-a884-440b-87a1-00aa0bf12dac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489c67e-2fe9-4a91-be22-f91c6ccb88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5), facecolor=[1,1,1])\n",
    "gs = fig.add_gridspec(1, 2, hspace=0)\n",
    "axs = gs.subplots()\n",
    "for i in range(2):\n",
    "    axs[i].set_xscale('log')\n",
    "    axs[i].set_yscale('log')\n",
    "\n",
    "axs[0].set_ylabel(r'Train Loss', fontsize=18)\n",
    "axs[1].set_ylabel(r'Test Loss', fontsize=18)\n",
    "    \n",
    "# Plot the training and test losses for each model.\n",
    "for model_type in labels:\n",
    "    plot_with_std(axs[0], dist_sd_ratios, train_loss[model_type], train_loss_std[model_type], labels[model_type])\n",
    "    plot_with_std(axs[1], dist_sd_ratios, test_loss[model_type], test_loss_std[model_type], labels[model_type])\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].axvline(x=np.sqrt(np.log(n_points)), color='red', linewidth=4, linestyle='-.', alpha=.8, label=r'$\\sqrt{\\log(n)}$')\n",
    "    axs[i].axvline(\n",
    "        x=np.sqrt(np.log(n_points)/np.sqrt(.5*n_points*(p+q))),\n",
    "        color='purple', linewidth=4, linestyle='-.', alpha=.8,\n",
    "        label=r'$\\sqrt{\\log(n)}/\\sqrt[4]{0.5n(p+q)}$')\n",
    "    # axs[i].axvline(\n",
    "    #     x=np.sqrt(np.log(n_points)/np.sqrt(n_points)),\n",
    "    #     color='violet', linewidth=4, linestyle='-.', alpha=1,\n",
    "    #     label=r'$\\sqrt{\\log(n)}/\\sqrt[4]{n}$')\n",
    "    axs[i].set_xlabel(r'$K = \\frac{\\Vert u-v \\Vert_2}{\\sigma}$', fontsize=18)\n",
    "    axs[i].legend()\n",
    "# fig.savefig(\"figures/synthetic_data_mlp_vs_gcn_loss_1conv_tt.pdf\", dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c3691-bbb4-47f1-97ea-4e11c60373f7",
   "metadata": {},
   "source": [
    "## Plot accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbae361-a809-4e42-b6d7-72d2dc4d0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5), facecolor=[1,1,1])\n",
    "gs = fig.add_gridspec(1, 2, hspace=0)\n",
    "axs = gs.subplots()\n",
    "for i in range(2):\n",
    "    axs[i].set_xscale('log')\n",
    "\n",
    "axs[0].set_ylabel(r'Train Accuracy', fontsize=18)\n",
    "axs[1].set_ylabel(r'Test Accuracy', fontsize=18)\n",
    "    \n",
    "# Plot the training and test losses for each model.\n",
    "for model_type in labels:\n",
    "    plot_with_std(axs[0], dist_sd_ratios, train_acc[model_type], train_acc_std[model_type], labels[model_type])\n",
    "    plot_with_std(axs[1], dist_sd_ratios, test_acc[model_type], test_acc_std[model_type], labels[model_type])\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].axvline(x=np.sqrt(np.log(n_points)), color='red', linewidth=4, linestyle='-.', alpha=.8, label=r'$\\sqrt{\\log(n)}$')\n",
    "    axs[i].axvline(\n",
    "        x=np.sqrt(np.log(n_points)/np.sqrt(.5*n_points*(p+q))),\n",
    "        color='purple', linewidth=4, linestyle='-.', alpha=.8,\n",
    "        label=r'$\\sqrt{\\log(n)}/\\sqrt[4]{0.5n(p+q)}$')\n",
    "#     axs[i].axvline(\n",
    "#         x=np.sqrt(np.log(n_points)/np.sqrt(n_points)),\n",
    "#         color='violet', linewidth=4, linestyle='-.', alpha=1,\n",
    "#         label=r'$\\sqrt{\\log(n)}/\\sqrt[4]{n}$')\n",
    "    axs[i].set_xlabel(r'$K = \\frac{\\Vert u-v \\Vert_2}{\\sigma}$', fontsize=18)\n",
    "    axs[i].legend()\n",
    "# fig.savefig(\"figures/synthetic_data_mlp_vs_gcn_acc_1conv_tt.pdf\", dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ea1db-e6a5-4879-b147-36277e7cec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5), facecolor=[1,1,1])\n",
    "gs = fig.add_gridspec(1, 2, hspace=0)\n",
    "axs = gs.subplots()\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_yscale('log')\n",
    "axs[1].set_xscale('log')\n",
    "\n",
    "axs[0].set_ylabel(r'Test Loss', fontsize=18)\n",
    "axs[1].set_ylabel(r'Test Accuracy', fontsize=18)\n",
    "    \n",
    "# Plot the training and test losses for each model.\n",
    "for model_type in labels:\n",
    "    plot_with_std(axs[0], dist_sd_ratios, test_loss[model_type], test_loss_std[model_type], labels[model_type])\n",
    "    plot_with_std(axs[1], dist_sd_ratios, test_acc[model_type], test_acc_std[model_type], labels[model_type])\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].axvline(x=np.sqrt(np.log(n_points)), color='red', linewidth=4, linestyle='-.', alpha=.8, label=r'$\\sqrt{\\log(n)}$')\n",
    "    axs[i].axvline(\n",
    "        x=np.sqrt(np.log(n_points)/np.sqrt(.5*n_points*(p+q))),\n",
    "        color='purple', linewidth=4, linestyle='-.', alpha=.8,\n",
    "        label=r'$\\sqrt{\\log(n)}/\\sqrt[4]{0.5n(p+q)}$')\n",
    "#     axs[i].axvline(\n",
    "#         x=np.sqrt(np.log(n_points)/np.sqrt(n_points)),\n",
    "#         color='violet', linewidth=4, linestyle='-.', alpha=1,\n",
    "#         label=r'$\\sqrt{\\log(n)}/\\sqrt[4]{n}$')\n",
    "    axs[i].set_xlabel(r'$K = \\frac{\\Vert u-v \\Vert_2}{\\sigma}$', fontsize=18)\n",
    "    axs[i].legend()\n",
    "# fig.savefig(\"figures/synthetic_data_mlp_vs_gcn_1conv.pdf\", dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d3379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
